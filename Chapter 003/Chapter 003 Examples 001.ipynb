{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 003 Examples 001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof A - Predict which desk at bank will serve the customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.66666667 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_true = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1]\n",
    "y_pred = [0, 1, 2, 3, 0, 1, 2, 3, 0, 2]\n",
    "rcs=recall_score(y_true, y_pred, average=None)\n",
    "print(rcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test >  0 :\n",
      "0 -> 0 = True\n",
      "0 -> 0 = True\n",
      "0 -> 0 = True\n",
      "Test >  1 :\n",
      "1 -> 1 = True\n",
      "1 -> 1 = True\n",
      "1 -> 2 = False\n",
      "Test >  2 :\n",
      "2 -> 2 = True\n",
      "2 -> 2 = True\n",
      "Test >  3 :\n",
      "3 -> 3 = True\n",
      "3 -> 3 = True\n"
     ]
    }
   ],
   "source": [
    "for i in range(rcs.shape[0]):\n",
    "    print('Test > %2d :' % i)\n",
    "    for j in range(len(y_true)):\n",
    "        if y_true[j] == i:\n",
    "            print(y_true[j], '->', y_pred[j], '=', y_true[j]==y_pred[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desk  0 : 100.000 % correct\n",
      "Desk  1 :  66.667 % correct\n",
      "Desk  2 : 100.000 % correct\n",
      "Desk  3 : 100.000 % correct\n"
     ]
    }
   ],
   "source": [
    "for i in range(rcs.shape[0]):\n",
    "    print('Desk %2d :' % i,'%7.3f %% correct' % (rcs[i]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof B - Predict which doctor at clinic will serve the customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_true = [0, 1, 2, 3, 0, 1, 2, 3, 0, 4]\n",
    "y_pred = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1]\n",
    "rcs=recall_score(y_true, y_pred, average=None)\n",
    "print(rcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test >  0 :\n",
      "0 -> 0 = True\n",
      "0 -> 0 = True\n",
      "0 -> 0 = True\n",
      "Test >  1 :\n",
      "1 -> 1 = True\n",
      "1 -> 1 = True\n",
      "Test >  2 :\n",
      "2 -> 2 = True\n",
      "2 -> 2 = True\n",
      "Test >  3 :\n",
      "3 -> 3 = True\n",
      "3 -> 3 = True\n",
      "Test >  4 :\n",
      "4 -> 1 = False\n"
     ]
    }
   ],
   "source": [
    "for i in range(rcs.shape[0]):\n",
    "    print('Test > %2d :' % i)\n",
    "    for j in range(len(y_true)):\n",
    "        if y_true[j] == i:\n",
    "            print(y_true[j], '->', y_pred[j], '=', y_true[j]==y_pred[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doctor  0 : 100.000 % correct\n",
      "Doctor  1 : 100.000 % correct\n",
      "Doctor  2 : 100.000 % correct\n",
      "Doctor  3 : 100.000 % correct\n",
      "Doctor  4 :   0.000 % correct\n"
     ]
    }
   ],
   "source": [
    "for i in range(rcs.shape[0]):\n",
    "    print('Doctor %2d :' % i,'%7.3f %% correct' % (rcs[i]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof C - Test if you have flu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of sick people who are correctly identified as having the condition\n",
      "Sensitivity : 100.000 % \n",
      "\n",
      "The percentage of healthy people who are correctly identified as not having the condition\n",
      "Specificity :  80.000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "sensitivity = tp / (tp+fn)\n",
    "specificity = tn / (tn+fp)\n",
    "\n",
    "print('The percentage of sick people who are correctly identified as having the condition')\n",
    "print('Sensitivity : %7.3f %%' % (sensitivity*100),'\\n')\n",
    "print('The percentage of healthy people who are correctly identified as not having the condition')\n",
    "print('Specificity : %7.3f %%' % (specificity*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof D  - Test if you have flu? What is the Precision score?\n",
    "### Precision is the ratio of properly predicted positive clarifications to the total predicted positive clarifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.83333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_true = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "print(precision_score(y_true, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof E - Test if you have flu? What is Negative predictive value (NPV)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative predictive value:  83.333 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "npv = tn / (tn+fn)\n",
    "print('Negative predictive value: %7.3f %%' % (npv*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof F - Test if you have flu? What is False negative rate (FNR) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negative rate:  20.000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "fnr = fp / (fn+tp)\n",
    "print('False negative rate: %7.3f %%' % (fnr*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof G - Test if you have flu? What is False positive rate (FPR)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate:  16.667 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "fpr = fp / (fp+tn)\n",
    "print('False positive rate: %7.3f %%' % (fpr*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof H - Test if you have flu? What is False discovery rate (FDR)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False discovery rate:  20.000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "fdr = fp / (fp+tp)\n",
    "print('False discovery rate: %7.3f %%' % (fdr*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof K - Test if you have flu? What is False omission rate (FOR)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False omission rate:  16.667 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "fomr = fn / (fn+tn)\n",
    "print('False omission rate: %7.3f %%' % (fomr*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof L  - Test if you have flu? What is Accuracy (ACC)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print('Accuracy: %7.3f %%' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof M - Compare the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.000 %\n",
      "Accuracy Count:   9 of  10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "print('Accuracy: %7.3f %%' % (accuracy_score(y_true, y_pred)*100))\n",
    "print('Accuracy Count: %3d of %3d' % (accuracy_score(y_true, y_pred, normalize=False),len(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  95.000 %\n",
      "Accuracy Count:  19 of  20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "print('Accuracy: %7.3f %%' % (accuracy_score(y_true, y_pred)*100))\n",
    "print('Accuracy Count: %3d of %3d' % (accuracy_score(y_true, y_pred, normalize=False),len(y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof N - F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  77.234 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = [0, 1, 2, 0, 1, 2 ,0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 0, 1 ,0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]\n",
    "print('F1 score: %7.3f %%' % (f1_score(y_true, y_pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof O - Matthews correlation coefficient (MCC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Corrcoef:  74.536 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef \n",
    "y_true = [+1, +1, +1, +1, +1, -1, +1, -1]\n",
    "y_pred = [-1, +1, +1, +1, +1, -1, +1, -1]\n",
    "print('Matthews Corrcoef: %7.3f %%' % (matthews_corrcoef(y_true, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof P - Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa:   0.831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "y_true = [+1, +1, +1, +1, +1, -1, +1, -1, +1, -1, +1, -1, +1]\n",
    "y_pred = [-1, +1, +1, +1, +1, -1, +1, -1, +1, -1, +1, -1, +1]\n",
    "print(\"Cohen's Kappa: %7.3f\" % (cohen_kappa_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof Q - Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa:   0.667 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "y_true = [0, 1, 2, 0, 1, 2 ,0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 0, 1 ,0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]\n",
    "print(\"Cohen's Kappa: %7.3f \" % (cohen_kappa_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof R - Bookmaker's Informedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate: 0.9\n",
      "True negative rate : 1.0\n",
      "Bookmaker Informedness: 0.8999999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0, 0, 0, 0,  0, 0, 0, 0, 0,  1, 1, 1, 1, 1, 1,  1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0,  0, 0, 0, 0, 0,  1, 1, 1, 1, 1, 1,  1, 1, 1, 0]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "tpr = tp / (tp+fn)\n",
    "print('True positive rate:', tpr)\n",
    "tnr = tn / (tn+fp)\n",
    "print('True negative rate :', tnr)\n",
    "bm=tpr+tnr-1\n",
    "print('Bookmaker Informedness:', bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof S - Markedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive predictive value: 0.9\n",
      "Negative predictive value: 0.9090909090909091\n",
      "Markedness: 0.8090909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [0, 0, 0, 0, 0,  0, 0, 0, 0, 0,  1, 1, 1, 1, 1, 1,  1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0,  0, 0, 0, 0, 0,  1, 1, 1, 1, 1, 1,  1, 1, 1, 0]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "ppv = tp / (tp+fn)\n",
    "print('Positive predictive value:', ppv)\n",
    "npv = tn / (tn+fn)\n",
    "print('Negative predictive value:', npv)\n",
    "mk=ppv+npv-1\n",
    "print('Markedness:', mk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
