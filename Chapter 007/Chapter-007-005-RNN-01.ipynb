{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apress - Industrialized Machine Learning Examples\n",
    "\n",
    "Andreas Francois Vermeulen\n",
    "2019\n",
    "\n",
    "### This is an example add-on to a book and needs to be accepted as part of that copyright."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter-007-005-RNN-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1968)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - Create Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output of sigmoid function to derivative\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C - Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset generation\n",
    "int2binary = {}\n",
    "binary_dim = 8\n",
    "\n",
    "largest_number = pow(2,binary_dim)\n",
    "binary = np.unpackbits(\n",
    "    np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D - Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input variables\n",
    "alpha = 0.1\n",
    "input_dim = 2\n",
    "hidden_dim = 16\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize neural network weights\n",
    "synapse_0 = 2*np.random.random((input_dim,hidden_dim)) - 1\n",
    "synapse_1 = 2*np.random.random((hidden_dim,output_dim)) - 1\n",
    "synapse_h = 2*np.random.random((hidden_dim,hidden_dim)) - 1\n",
    "\n",
    "synapse_0_update = np.zeros_like(synapse_0)\n",
    "synapse_1_update = np.zeros_like(synapse_1)\n",
    "synapse_h_update = np.zeros_like(synapse_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E - Run RNN Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Cycle: 0\n",
      "===============================================\n",
      "Error:[4.02807328]\n",
      "Pred:[0 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 1 1 1 0 0]\n",
      "123 + 33 = 1\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 1000\n",
      "===============================================\n",
      "Error:[3.9318002]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 1 1 0 0 1 0]\n",
      "42 + 8 = 0\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 2000\n",
      "===============================================\n",
      "Error:[4.02566846]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 1 0 1 1 0 1]\n",
      "57 + 52 = 0\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 3000\n",
      "===============================================\n",
      "Error:[4.16074906]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 1 0 1 0 1]\n",
      "61 + 88 = 255\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 4000\n",
      "===============================================\n",
      "Error:[3.17246251]\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "39 + 80 = 127\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 5000\n",
      "===============================================\n",
      "Error:[2.72587023]\n",
      "Pred:[0 0 1 1 1 0 0 0]\n",
      "True:[0 0 1 0 0 0 0 0]\n",
      "18 + 14 = 56\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 6000\n",
      "===============================================\n",
      "Error:[1.26003367]\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "9 + 71 = 80\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 7000\n",
      "===============================================\n",
      "Error:[0.65050984]\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "6 + 75 = 81\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 8000\n",
      "===============================================\n",
      "Error:[0.63824183]\n",
      "Pred:[0 1 0 0 1 0 1 1]\n",
      "True:[0 1 0 0 1 0 1 1]\n",
      "30 + 45 = 75\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 9000\n",
      "===============================================\n",
      "Error:[0.49285371]\n",
      "Pred:[0 1 1 1 1 1 0 0]\n",
      "True:[0 1 1 1 1 1 0 0]\n",
      "118 + 6 = 124\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 10000\n",
      "===============================================\n",
      "Error:[0.47873812]\n",
      "Pred:[1 0 1 0 1 1 0 0]\n",
      "True:[1 0 1 0 1 1 0 0]\n",
      "118 + 54 = 172\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 11000\n",
      "===============================================\n",
      "Error:[0.20791752]\n",
      "Pred:[0 0 0 0 1 0 1 0]\n",
      "True:[0 0 0 0 1 0 1 0]\n",
      "5 + 5 = 10\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 12000\n",
      "===============================================\n",
      "Error:[0.47311252]\n",
      "Pred:[1 0 0 1 0 0 0 0]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "123 + 21 = 144\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 13000\n",
      "===============================================\n",
      "Error:[0.28725484]\n",
      "Pred:[0 1 1 1 0 0 0 0]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "21 + 91 = 112\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 14000\n",
      "===============================================\n",
      "Error:[0.22562027]\n",
      "Pred:[1 1 0 1 0 0 0 1]\n",
      "True:[1 1 0 1 0 0 0 1]\n",
      "89 + 120 = 209\n",
      "===============================================\n",
      "===============================================\n",
      "Cycle: 15000\n",
      "===============================================\n",
      "Error:[0.28329856]\n",
      "Pred:[1 0 0 1 1 0 0 1]\n",
      "True:[1 0 0 1 1 0 0 1]\n",
      "63 + 90 = 153\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "# training logic\n",
    "for j in range(15001):\n",
    "    \n",
    "    # generate a simple addition problem (a + b = c)\n",
    "    a_int = np.random.randint(largest_number/2) # int version\n",
    "    a = int2binary[a_int] # binary encoding\n",
    "\n",
    "    b_int = np.random.randint(largest_number/2) # int version\n",
    "    b = int2binary[b_int] # binary encoding\n",
    "\n",
    "    # true answer\n",
    "    c_int = a_int + b_int\n",
    "    c = int2binary[c_int]\n",
    "    \n",
    "    # where we'll store our best guess (binary encoded)\n",
    "    d = np.zeros_like(c)\n",
    "\n",
    "    overallError = 0\n",
    "    \n",
    "    layer_2_deltas = list()\n",
    "    layer_1_values = list()\n",
    "    layer_1_values.append(np.zeros(hidden_dim))\n",
    "    \n",
    "    # moving along the positions in the binary encoding\n",
    "    for position in range(binary_dim):\n",
    "        \n",
    "        # generate input and output\n",
    "        X = np.array([[a[binary_dim - position - 1],b[binary_dim - position - 1]]])\n",
    "        y = np.array([[c[binary_dim - position - 1]]]).T\n",
    "\n",
    "        # hidden layer (input ~+ prev_hidden)\n",
    "        layer_1 = sigmoid(np.dot(X,synapse_0) + np.dot(layer_1_values[-1],synapse_h))\n",
    "\n",
    "        # output layer (new binary representation)\n",
    "        layer_2 = sigmoid(np.dot(layer_1,synapse_1))\n",
    "\n",
    "        # did we miss?... if so, by how much?\n",
    "        layer_2_error = y - layer_2\n",
    "        layer_2_deltas.append((layer_2_error)*sigmoid_output_to_derivative(layer_2))\n",
    "        overallError += np.abs(layer_2_error[0])\n",
    "    \n",
    "        # decode estimate so we can print it out\n",
    "        d[binary_dim - position - 1] = np.round(layer_2[0][0])\n",
    "        \n",
    "        # store hidden layer so we can use it in the next timestep\n",
    "        layer_1_values.append(copy.deepcopy(layer_1))\n",
    "    \n",
    "    future_layer_1_delta = np.zeros(hidden_dim)\n",
    "    \n",
    "    for position in range(binary_dim):\n",
    "        \n",
    "        X = np.array([[a[position],b[position]]])\n",
    "        layer_1 = layer_1_values[-position-1]\n",
    "        prev_layer_1 = layer_1_values[-position-2]\n",
    "        \n",
    "        # error at output layer\n",
    "        layer_2_delta = layer_2_deltas[-position-1]\n",
    "        # error at hidden layer\n",
    "        layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + layer_2_delta.dot(synapse_1.T)) * sigmoid_output_to_derivative(layer_1)\n",
    "\n",
    "        # let's update all our weights so we can try again\n",
    "        synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_delta)\n",
    "        synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)\n",
    "        synapse_0_update += X.T.dot(layer_1_delta)\n",
    "        \n",
    "        future_layer_1_delta = layer_1_delta\n",
    "    \n",
    "\n",
    "    synapse_0 += synapse_0_update * alpha\n",
    "    synapse_1 += synapse_1_update * alpha\n",
    "    synapse_h += synapse_h_update * alpha    \n",
    "\n",
    "    synapse_0_update *= 0\n",
    "    synapse_1_update *= 0\n",
    "    synapse_h_update *= 0\n",
    "    \n",
    "    # print out progress\n",
    "    if(j % 1000 == 0):\n",
    "        print ('===============================================')\n",
    "        print ('Cycle:', j)\n",
    "        print ('===============================================')\n",
    "        print ('Error:' + str(overallError))\n",
    "        print ('Pred:' + str(d))\n",
    "        print ('True:' + str(c))\n",
    "        out = 0\n",
    "        for index,x in enumerate(reversed(d)):\n",
    "            out += x*pow(2,index)\n",
    "        print (str(a_int) + ' + ' + str(b_int) + ' = ' + str(out))\n",
    "        print ('===============================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print('Done!',str(now))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
