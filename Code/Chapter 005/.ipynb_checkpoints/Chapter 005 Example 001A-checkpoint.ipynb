{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apress - Industrialized Machine Learning Examples\n",
    "\n",
    "Andreas Francois Vermeulen\n",
    "2019\n",
    "\n",
    "### This is an example add-on to a book and needs to be accepted as part of that copyright."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 05 Example 001A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfeature=['F01', 'F02', 'F04']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - Load the Roses dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AndreVermeulen\\Documents\\My Book\\apress\\Industrial Machine Learning\\book\\GitHub\\Upload\\industrial-machine-learning\\Data\\Roses02.csv\n"
     ]
    }
   ],
   "source": [
    "fileName = '../../Data/Roses02.csv'\n",
    "fileFullName = os.path.abspath(fileName)\n",
    "print(fileFullName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 6)\n",
      "Index(['F01', 'F02', 'F03', 'F04', 'T01', 'T02'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "datadf= pd.read_csv(fileFullName, header=0)\n",
    "print(datadf.shape)\n",
    "print(datadf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = datadf[sfeature].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X2 = np.array(data_X,dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = datadf['T01'].copy(deep=True)\n",
    "data_y.columns = (['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y2 = np.array(data_y,dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C - Select Training and Test Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_X2, data_y2, train_size=0.7, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D - Build Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = StandardScaler(copy=True, with_mean=True, with_std=False)\n",
    "scaler = transformer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.009 3.395 0.152] [-0.81441667  0.32359048 -1.06877619]\n"
     ]
    }
   ],
   "source": [
    "X_train_scale = scaler.transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "print(X_train[0],X_train_scale[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy': True, 'with_mean': True, 'with_std': False}\n"
     ]
    }
   ],
   "source": [
    "print(scaler.get_params(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 3\n",
      "Samples: 420\n",
      "Scale: None\n",
      "Mean: [5.82341667 3.07140952 1.22077619]\n",
      "variance: None\n"
     ]
    }
   ],
   "source": [
    "s=np.array(scaler.mean_)\n",
    "print('Features:', s.shape[0])\n",
    "print('Samples:', scaler.n_samples_seen_)\n",
    "print('Scale:', scaler.scale_)\n",
    "print('Mean:',scaler.mean_ )\n",
    "print('variance:',scaler.var_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E - Build Base ML using Support Vector Classification (SVC) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(max_iter=5000, \n",
    "        gamma='auto', \n",
    "        class_weight='balanced', \n",
    "        probability=True, \n",
    "        kernel='linear', \n",
    "        random_state=0, \n",
    "        verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part F - Execute AdaBoost = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = AdaBoostClassifier(algorithm='SAMME', \n",
    "                          n_estimators=1, \n",
    "                          base_estimator=svc, \n",
    "                          learning_rate=1, \n",
    "                          random_state=0)\n",
    "\n",
    "clf1.fit(X_train_scale, y_train)\n",
    "\n",
    "score1 = clf1.score(X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:   0 > 1\n",
      "Class:   1 > 2\n",
      "Class:   2 > 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(clf1.n_classes_):\n",
    "    print('Class: %3d > %s' % (i, clf1.classes_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator 001 > weight: 1.34373 and error: 0.34286\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clf1.estimator_weights_)):\n",
    "    print('Estimator %03d > weight: %7.5f and error: %7.5f' % ((i+1), clf1.estimator_weights_[i],clf1.estimator_errors_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for AdaBoost (1): 67.2222 %\n"
     ]
    }
   ],
   "source": [
    "print('Results for AdaBoost (1): %7.4f %%' % (score1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part G - Execute AdaBoost = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = AdaBoostClassifier(algorithm='SAMME', n_estimators=5, base_estimator=svc, learning_rate=1, random_state=0)\n",
    "clf2.fit(X_train_scale, y_train)\n",
    "score2 = clf2.score(X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator 001 > weight: 1.34373 and error: 0.34286\n",
      "Estimator 002 > weight: 1.34491 and error: 0.34259\n",
      "Estimator 003 > weight: 1.34602 and error: 0.34234\n",
      "Estimator 004 > weight: 1.30833 and error: 0.35088\n",
      "Estimator 005 > weight: 1.38629 and error: 0.33333\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clf2.estimator_weights_)):\n",
    "    print('Estimator %03d > weight: %7.5f and error: %7.5f' % ((i+1), clf2.estimator_weights_[i],clf2.estimator_errors_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for AdaBoost (5): 67.7778 %\n"
     ]
    }
   ],
   "source": [
    "print('Results for AdaBoost (5): %7.4f %%'% (score2*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part H - Execute AdaBoost = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = AdaBoostClassifier(algorithm='SAMME', n_estimators=10, base_estimator=svc, learning_rate=1, random_state=0)\n",
    "clf3.fit(X_train_scale, y_train)\n",
    "score3 = clf3.score(X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator 001 > weight: 1.34373 and error: 0.34286\n",
      "Estimator 002 > weight: 1.34491 and error: 0.34259\n",
      "Estimator 003 > weight: 1.34602 and error: 0.34234\n",
      "Estimator 004 > weight: 1.30833 and error: 0.35088\n",
      "Estimator 005 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 006 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 007 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 008 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 009 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 010 > weight: 1.38629 and error: 0.33333\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clf3.estimator_weights_)):\n",
    "    print('Estimator %03d > weight: %7.5f and error: %7.5f' % ((i+1), clf3.estimator_weights_[i],clf3.estimator_errors_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for AdaBoost (10): 73.33333 %\n"
     ]
    }
   ],
   "source": [
    "print('Results for AdaBoost (10): %7.5f %%'% (score3*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I - Execute AdaBoost = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = AdaBoostClassifier(algorithm='SAMME', n_estimators=20, base_estimator=svc, learning_rate=1, random_state=0)\n",
    "clf4.fit(X_train_scale, y_train)\n",
    "score4 = clf4.score(X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator 001 > weight: 1.34373 and error: 0.34286\n",
      "Estimator 002 > weight: 1.34491 and error: 0.34259\n",
      "Estimator 003 > weight: 1.34602 and error: 0.34234\n",
      "Estimator 004 > weight: 1.30833 and error: 0.35088\n",
      "Estimator 005 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 006 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 007 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 008 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 009 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 010 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 011 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 012 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 013 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 014 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 015 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 016 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 017 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 018 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 019 > weight: 1.38629 and error: 0.33333\n",
      "Estimator 020 > weight: 1.38629 and error: 0.33333\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clf4.estimator_weights_)):\n",
    "    print('Estimator %03d > weight: %7.5f and error: %7.5f' % ((i+1), clf4.estimator_weights_[i],clf4.estimator_errors_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for AdaBoost (20): 73.3333 %\n"
     ]
    }
   ],
   "source": [
    "print('Results for AdaBoost (20): %7.4f %%'% (score4*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part J - Improvement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score improvement (67.220 % to 73.330 %), so a 9.090 % improvement!\n"
     ]
    }
   ],
   "source": [
    "s1=round(score1,4)\n",
    "s4=round(score4,4)\n",
    "print('Score improvement (%5.3f %% to %5.3f %%), so a %5.3f %% improvement!' % (s1*100,s4*100,((s4-s1)/s1)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! 2019-10-19 17:41:36.583454\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print('Done!',str(now))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
