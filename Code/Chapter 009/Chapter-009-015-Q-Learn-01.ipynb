{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apress - Industrialized Machine Learning Examples\n",
    "\n",
    "Andreas Francois Vermeulen\n",
    "2019\n",
    "\n",
    "### This is an example add-on to a book and needs to be accepted as part of that copyright."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8X8WoA090Yf"
   },
   "source": [
    "## Chapter-009-015-Q-Learn-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6i-5O0kK90Yg"
   },
   "source": [
    "### Install keras-rl library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3508,
     "status": "ok",
     "timestamp": 1547296907105,
     "user": {
      "displayName": "Andre Vermeulen",
      "photoUrl": "",
      "userId": "07958753266952227006"
     },
     "user_tz": 0
    },
    "id": "M1EtbsJL90Yi",
    "outputId": "1b39ce79-c31e-4326-e385-695a0f62ea2d"
   },
   "outputs": [],
   "source": [
    "#!pip install keras-rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6975,
     "status": "ok",
     "timestamp": 1547296910585,
     "user": {
      "displayName": "Andre Vermeulen",
      "photoUrl": "",
      "userId": "07958753266952227006"
     },
     "user_tz": 0
    },
    "id": "L8BGzFvwCCHf",
    "outputId": "fcea7570-6c0f-48ed-ab81-7470bc00c0d9"
   },
   "outputs": [],
   "source": [
    "#!pip install pyglet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPbJABoQ90Yk"
   },
   "source": [
    "### Install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11310,
     "status": "ok",
     "timestamp": 1547296914931,
     "user": {
      "displayName": "Andre Vermeulen",
      "photoUrl": "",
      "userId": "07958753266952227006"
     },
     "user_tz": 0
    },
    "id": "czKZen-V90Yl",
    "outputId": "28d7c907-818f-4e06-8845-ff0463c29c1b"
   },
   "outputs": [],
   "source": [
    "#!pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYnz7vPx90Yr"
   },
   "source": [
    " ### Install dependencies for CartPole environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15357,
     "status": "ok",
     "timestamp": 1547296918990,
     "user": {
      "displayName": "Andre Vermeulen",
      "photoUrl": "",
      "userId": "07958753266952227006"
     },
     "user_tz": 0
    },
    "id": "zePbmymd90Ys",
    "outputId": "e2473c06-09f3-4224-f9ae-ec051950d3e5"
   },
   "outputs": [],
   "source": [
    "#!pip install gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CgxW89vg90Yv"
   },
   "source": [
    "# You are ready to perform the Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wc-MuFJJ90Yv"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7f0_cd6l90Y1"
   },
   "source": [
    "You need to set several variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZeuOxo6z90Y1"
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'CartPole-v0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3_fLaOF90Y4"
   },
   "source": [
    "Get the environment and extract the number of actions available in the Cartpole problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15326,
     "status": "ok",
     "timestamp": 1547296918993,
     "user": {
      "displayName": "Andre Vermeulen",
      "photoUrl": "",
      "userId": "07958753266952227006"
     },
     "user_tz": 0
    },
    "id": "JQMSKzqK90Y5",
    "outputId": "5c306122-2861-482b-e4cb-2c58500c6b70"
   },
   "outputs": [],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(20)\n",
    "env.seed(20)\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wiatn9a790Y7"
   },
   "source": [
    "Create a single hidden layer neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYzRl7yc90Y8"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15764,
     "status": "ok",
     "timestamp": 1547296919446,
     "user": {
      "displayName": "Andre Vermeulen",
      "photoUrl": "",
      "userId": "07958753266952227006"
     },
     "user_tz": 0
    },
    "id": "LbohKsit90Y_",
    "outputId": "32aaa82e-0569-4a5d-cabb-b3ba24c73cdb"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YWYNd_Rs90ZC"
   },
   "source": [
    "Next you configure and compile our agent. Suggest you use the policy as Epsilon Greedy and you set the memory as Sequential Memory because you must to store the result of actions you Cart performed and the rewards it gets for each action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEjBDdgH90ZD"
   },
   "outputs": [],
   "source": [
    "policy = EpsGreedyQPolicy()\n",
    "\n",
    "memory = SequentialMemory(limit=50000, \n",
    "                          window_length=1\n",
    "                         )\n",
    "\n",
    "dqn = DQNAgent(model=model, \n",
    "               nb_actions=nb_actions, \n",
    "               memory=memory, \n",
    "               nb_steps_warmup=1000, \n",
    "               target_model_update=1e-2, \n",
    "               policy=policy,\n",
    "               enable_dueling_network=False,\n",
    "               dueling_type='avg'\n",
    "              )\n",
    "\n",
    "dqn.compile(Adam(lr=1e-3), \n",
    "            metrics=['mae']\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1J_Pjlt90ZG"
   },
   "source": [
    "Time to perform the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30500,
     "status": "ok",
     "timestamp": 1547296934191,
     "user": {
      "displayName": "Andre Vermeulen",
      "photoUrl": "",
      "userId": "07958753266952227006"
     },
     "user_tz": 0
    },
    "id": "r0osd6ba90ZH",
    "outputId": "ede6af2a-4a6d-4cd9-d27b-1897b46296ee"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  dqn.fit(env, nb_steps=5000, visualize=True, verbose=2)\n",
    "except:\n",
    "  dqn.fit(env, nb_steps=5000, visualize=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 750,
     "status": "ok",
     "timestamp": 1547297393963,
     "user": {
      "displayName": "Andre Vermeulen",
      "photoUrl": "",
      "userId": "07958753266952227006"
     },
     "user_tz": 0
    },
    "id": "xBVgeLRODNgG",
    "outputId": "a99a7286-5c10-4bc5-a653-f0b008be8f86"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  dqn.test(env, nb_episodes=5, visualize=True, verbose=2)\n",
    "except:\n",
    "  dqn.test(env, nb_episodes=5, visualize=False, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print('Done!',str(now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGaJ1fOZ90ZK"
   },
   "source": [
    "Your can now test the reinforcement learning model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Chapter-04-013-Q-Learn-01.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
