{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apress - Industrialized Machine Learning Examples\n",
    "\n",
    "Andreas Francois Vermeulen\n",
    "2019\n",
    "\n",
    "### This is an example add-on to a book and needs to be accepted as part of that copyright."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 005 Example 005B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile= '../../data/Roses04_TrainSet.csv'\n",
    "testfile='../../data/Roses04_TestSet.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NameColumns = [\n",
    "        'SepalLength', \n",
    "        'SepalWidth',\n",
    "        'PetalLength', \n",
    "        'PetalWidth', \n",
    "        'Species'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = pd.read_csv(trainfile, names=NameColumns, header=0)\n",
    "train_x = training_dataset.iloc[:, 0:4]\n",
    "train_y = training_dataset.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(testfile, names=NameColumns, header=0)\n",
    "test_x = test_dataset.iloc[:, 0:4]\n",
    "test_y = test_dataset.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_feat = [\n",
    "    tf.feature_column.numeric_column(key=NameColumns[0]),\n",
    "    tf.feature_column.numeric_column(key=NameColumns[1]),\n",
    "    tf.feature_column.numeric_column(key=NameColumns[2]),\n",
    "    tf.feature_column.numeric_column(key=NameColumns[3])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network - Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ANDREV~1\\AppData\\Local\\Temp\\tmpjmw33jhl\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ANDREV~1\\\\AppData\\\\Local\\\\Temp\\\\tmpjmw33jhl', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021967F9AC18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=columns_feat,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[10, 10],\n",
    "    # The model is classifying 3 classes\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(inputs, outputs, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(inputs), outputs))\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model Now with Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AndreVermeulen\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\AndreVermeulen\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\ANDREV~1\\AppData\\Local\\Temp\\tmpjmw33jhl\\model.ckpt.\n",
      "INFO:tensorflow:loss = 147528.5, step = 1\n",
      "INFO:tensorflow:global_step/sec: 129.034\n",
      "INFO:tensorflow:loss = 379.3532, step = 101 (0.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.952\n",
      "INFO:tensorflow:loss = 389.33173, step = 201 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.13\n",
      "INFO:tensorflow:loss = 158.5455, step = 301 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.339\n",
      "INFO:tensorflow:loss = 247.85095, step = 401 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.628\n",
      "INFO:tensorflow:loss = 79.23622, step = 501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.738\n",
      "INFO:tensorflow:loss = 160.27095, step = 601 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.872\n",
      "INFO:tensorflow:loss = 411.89093, step = 701 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.633\n",
      "INFO:tensorflow:loss = 156.5441, step = 801 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.693\n",
      "INFO:tensorflow:loss = 174.44794, step = 901 (0.298 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\ANDREV~1\\AppData\\Local\\Temp\\tmpjmw33jhl\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 278.4077.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x2195a4d3470>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda:train_function(train_x, train_y, 100),\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_function(attributes, classes, batch_size):\n",
    "    attributes=dict(attributes)\n",
    "    if classes is None:\n",
    "        inputs = attributes\n",
    "    else:\n",
    "        inputs = (attributes, classes)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    assert batch_size is not None, \"batch_size can not be None, please fix\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model with Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-14T10:26:07Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\AndreVermeulen\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ANDREV~1\\AppData\\Local\\Temp\\tmpjmw33jhl\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-14-10:26:08\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.93333334, average_loss = 4.0856304, global_step = 1000, loss = 122.56891\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\ANDREV~1\\AppData\\Local\\Temp\\tmpjmw33jhl\\model.ckpt-1000\n",
      "\n",
      "Accuracy: 0.9333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:evaluation_function(test_x, test_y, 100))\n",
    "\n",
    "print('\\nAccuracy: {accuracy:0.4f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! 2019-04-14 11:26:09.737850\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print('Done!',str(now))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
